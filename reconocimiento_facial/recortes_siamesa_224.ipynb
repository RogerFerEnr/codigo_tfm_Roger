{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addf31e6-1132-49cc-8a97-0f10838b9afa",
   "metadata": {},
   "source": [
    "#### Vamos a entrenar una red siamesa pero usando ahora recortes particulares de las caras (Vamos a probar si esto es capaz de mejorar el rendimiento del modelo) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e719111-ee56-4fec-a898-b14e25a78ff5",
   "metadata": {},
   "source": [
    "### Cargamos las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ce051c-f333-4b12-908a-be40596ed86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:02:33.613905: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.metrics import Precision, Recall, Accuracy\n",
    "\n",
    "\n",
    "# Importamos algunas dependencias fundamentales de la API de tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf\n",
    "\n",
    "import mtcnn\n",
    "from mtcnn.mtcnn import MTCNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce60fd48-47f6-4924-8ab7-f1b3a3aa8f64",
   "metadata": {},
   "source": [
    "#### Creamos los directorios para almacenar los recortes de las caras. Cada recorte de cara se redimensiona a tamaño 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7370503-d153-465d-87e5-9256c7fad616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos la ruta actual\n",
    "ruta_actual = os.getcwd()\n",
    "\n",
    "#Definimos las rutas de los directorios que vamos a crear\n",
    "ruta_recortes_caras = os.path.join(ruta_actual,\"recortes_224\")\n",
    "ruta_recortes_entrenamiento = os.path.join(ruta_recortes_caras,\"entrenamiento\")\n",
    "ruta_recortes_test = os.path.join(ruta_recortes_caras,\"test\")\n",
    "\n",
    "#Creamos los directorios para almacenar las recortes de las caras de las imágenes y los redimensionamos a tamaño 105x105\n",
    "try:\n",
    "    os.mkdir(ruta_recortes_caras)\n",
    "except:\n",
    "    print(\"La carpeta ya existe\")\n",
    "\n",
    "#Creamos la carpeta para almacenar los recortes de entrenamiento\n",
    "try:\n",
    "    os.mkdir(ruta_recortes_entrenamiento)\n",
    "except:\n",
    "    print(\"La carpeta ya existe\")\n",
    "\n",
    "#Creamos la carpeta para almacenar los recortes de test\n",
    "try:\n",
    "    os.mkdir(ruta_recortes_test)\n",
    "except:\n",
    "    print(\"La carpeta ya existe\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b72fe-ad71-4f2f-801e-5c307e076a70",
   "metadata": {},
   "source": [
    "#### Definimos los directorios originales que contienen las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e8a462-424c-4fe4-9233-df51ef08acc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:02:34.841078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-22 15:02:34.858707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-22 15:02:34.858812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-22 15:02:34.859151: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-22 15:02:34.860327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-22 15:02:34.860405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-22 15:02:34.860457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-22 15:02:35.139739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-22 15:02:35.139836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-22 15:02:35.139895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-22 15:02:35.139956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1028 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hubo 15140 imágenes de entrenamiento en las que no se pudiero extraer recortes de las caras\n"
     ]
    }
   ],
   "source": [
    "ruta_original_entrenamiento = os.path.join(ruta_actual,\"vggface2_train\",\"train\")\n",
    "ruta_original_test = os.path.join(ruta_actual,\"vggface2_test\",\"test\")\n",
    "\n",
    "lista_personas_entrenamiento = os.listdir(ruta_original_entrenamiento) \n",
    "lista_personas_test = os.listdir(ruta_original_test)\n",
    "\n",
    "#Se hara un resize de las imágenes al tamaño de entrada de la red.\n",
    "tamano_resize = 224\n",
    "contador = 0 #Contamos las imágenes de las que no se pudo extraer cara\n",
    "\n",
    "#Extraemos los recortes para el conjunto de entrenamiento\n",
    "for persona in lista_personas_entrenamiento:\n",
    "\n",
    "    #Creamos la carpeta para almacenar los recortes de las caras\n",
    "    ruta_recortes_entrenamiento_persona = os.path.join(ruta_recortes_entrenamiento,persona) \n",
    "    try:\n",
    "        os.mkdir(ruta_recortes_entrenamiento_persona)\n",
    "    except:\n",
    "        print(\"La carpeta ya estaba creada\")\n",
    "    \n",
    "    lista_imagenes_personas = os.listdir(os.path.join(ruta_original_entrenamiento,persona))\n",
    "\n",
    "    for nombre_imagen in lista_imagenes_personas:\n",
    "        #ruta a la imagen\n",
    "        ruta_imagen = os.path.join(ruta_original_entrenamiento,persona,nombre_imagen)\n",
    "        \n",
    "        # Cargamos la imagen usando OpenCV\n",
    "        imagen = cv2.imread(ruta_imagen)\n",
    "\n",
    "        #Convertimos la imagen de BGR a RGB\n",
    "        imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Inicializamos el detector de caras de MTCNN\n",
    "        detector = MTCNN()\n",
    "\n",
    "        # Detectamos las caras en la imagen\n",
    "        resultados = detector.detect_faces(imagen_rgb)\n",
    "        \n",
    "        # Verificar si se detectó al menos una cara\n",
    "        if len(resultados) > 0:\n",
    "        # Obtenemos las coordenadas de la primera cara detectada (rectángulo)\n",
    "            x, y, ancho, alto = resultados[0]['box']\n",
    "    \n",
    "        # Extraemos la región de la cara de la imagen original\n",
    "            cara = imagen_rgb[y:y+alto, x:x+ancho]\n",
    "            cara_redimensionada = cv2.resize(cara, (tamano_resize, tamano_resize))\n",
    "\n",
    "            # Convertimos la imagen de nuevo a BGR para guardar con OpenCV\n",
    "            cara_redimensionada_bgr = cv2.cvtColor(cara_redimensionada, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            ruta_guardado = os.path.join(ruta_recortes_entrenamiento_persona,nombre_imagen)\n",
    "            cv2.imwrite(ruta_guardado, cara_redimensionada_bgr)\n",
    "\n",
    "        else:\n",
    "            contador=contador+1\n",
    "\n",
    "print(f\"Hubo {contador} imágenes de entrenamiento en las que no se pudiero extraer recortes de las caras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a188c80c-a7a8-4157-9f56-91cabf9b1a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hubo 983 imágenes de test en las que no se pudieron extraer los recortes de las caras\n"
     ]
    }
   ],
   "source": [
    "#Extraemos los recortes para el conjunto de test\n",
    "\n",
    "contador = 0\n",
    "\n",
    "for persona in lista_personas_test:\n",
    "\n",
    "    #Creamos la carpeta para almacenar los recortes de las caras\n",
    "    ruta_recortes_test_persona = os.path.join(ruta_recortes_test,persona) \n",
    "    try:\n",
    "        os.mkdir(ruta_recortes_test_persona)\n",
    "    except:\n",
    "        print(\"La carpeta ya estaba creada\")\n",
    "    \n",
    "    lista_imagenes_personas = os.listdir(os.path.join(ruta_original_test,persona))\n",
    "\n",
    "    for nombre_imagen in lista_imagenes_personas:\n",
    "        #ruta a la imagen\n",
    "        ruta_imagen = os.path.join(ruta_original_test,persona,nombre_imagen)\n",
    "        \n",
    "        # Cargamos la imagen usando OpenCV\n",
    "        imagen = cv2.imread(ruta_imagen)\n",
    "\n",
    "        #Convertimos la imagen de BGR a RGB\n",
    "        imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Inicializamos el detector de caras de MTCNN\n",
    "        detector = MTCNN()\n",
    "\n",
    "        # Detectamos las caras en la imagen\n",
    "        resultados = detector.detect_faces(imagen_rgb)\n",
    "        \n",
    "        # Verificar si se detectó al menos una cara\n",
    "        if len(resultados) > 0:\n",
    "        # Obtenemos las coordenadas de la primera cara detectada (rectángulo)\n",
    "            x, y, ancho, alto = resultados[0]['box']\n",
    "    \n",
    "        # Extraemos la región de la cara de la imagen original\n",
    "            cara = imagen_rgb[y:y+alto, x:x+ancho]\n",
    "            cara_redimensionada = cv2.resize(cara, (tamano_resize, tamano_resize))\n",
    "\n",
    "            # Convertimos la imagen de nuevo a BGR para guardar con OpenCV\n",
    "            cara_redimensionada_bgr = cv2.cvtColor(cara_redimensionada, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            ruta_guardado = os.path.join(ruta_recortes_test_persona,nombre_imagen)\n",
    "            cv2.imwrite(ruta_guardado, cara_redimensionada_bgr)\n",
    "\n",
    "        else:\n",
    "            contador=contador+1\n",
    "\n",
    "print(f\"Hubo {contador} imágenes de test en las que no se pudieron extraer los recortes de las caras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73675a28-5ade-494b-a80e-5d1a3b710e7a",
   "metadata": {},
   "source": [
    "#### Contamos el mínimo número de imágenes disponibles para cualquiera de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5b5ddf-b934-4a10-a4fa-07d419eb9120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mínimo de imágenes por clase es 87\n"
     ]
    }
   ],
   "source": [
    "minimo = 100000 #Ninguna clase tiene tantas imágenes\n",
    "for elemento in os.listdir(ruta_recortes_entrenamiento):\n",
    "    numero_imagenes_elemento = len(os.listdir(os.path.join(ruta_recortes_entrenamiento,elemento)))\n",
    "\n",
    "    if minimo > numero_imagenes_elemento:\n",
    "        minimo = numero_imagenes_elemento\n",
    "\n",
    "print(f\"El mínimo de imágenes por clase es {minimo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be99b8c-0028-473c-8888-46bb07f5358c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mínimo de imágenes por clase es 98\n"
     ]
    }
   ],
   "source": [
    "minimo = 100000 #Ninguna clase tiene tantas imágenes\n",
    "for elemento in os.listdir(ruta_recortes_test):\n",
    "    numero_imagenes_elemento = len(os.listdir(os.path.join(ruta_recortes_test,elemento)))\n",
    "\n",
    "    if minimo > numero_imagenes_elemento:\n",
    "        minimo = numero_imagenes_elemento\n",
    "\n",
    "print(f\"El mínimo de imágenes por clase es {minimo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc27ed-ffe3-4785-b91a-cfd1b1da7264",
   "metadata": {},
   "source": [
    "#### Para cada persona del dataset tenemos al menos 87 imágenes de su cara."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
